{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why CNN?\n",
    "- Because image dimension is large, to shrink that dimension to better useful feature\n",
    "- To sparse of connection in NN\n",
    "- **Parameter Sharing**: A feature detector (such as a vertical edge detector, and so on) that's useful in one part of the image is probably useful in another part of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge Detection\n",
    "Using Convolution process to generate the edge from raw picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobel_kernel = [\n",
    "    [1, 0, -1],\n",
    "    [2, 0, -2],\n",
    "    [1, 0, -1]\n",
    "]\n",
    "\n",
    "scharr_filter = [\n",
    "    [3, 0, -3],\n",
    "    [10, 0, -10],\n",
    "    [3, 0, -3]\n",
    "]\n",
    "\n",
    "# filter size always odd\n",
    "# input_image * kernel\n",
    "# * means convolutional process\n",
    "# convolution using tensorflow: tf.nn.conv2d or keras: conv2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution in CNN\n",
    "- trainable fill in the filter\n",
    "- to find best filter for generating edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding\n",
    "- to be able the filter scanning all of the entire image. so there is no missing features\n",
    "- padding usually define with p symbol\n",
    "\n",
    "\n",
    "padding result dimension = (n + 2p - f + 1) x (n + 2p - f + 1)\n",
    "- n = input dimension\n",
    "- p = padding\n",
    "- f = filter size\n",
    "\n",
    "### Padding Type\n",
    "- valid convolution: no padding\n",
    "- same convolution: padding the input image so that output size is the same as the input size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strided Convolution\n",
    "Strided Convolution is step that move the filter over the entire pixel images.\n",
    "<br>\n",
    "<br>\n",
    "strided picture dimension = ((n + 2p - f) / s) + 1 # round down if not integer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution on RGB images\n",
    "\n",
    "Filter size = n \\* n * color channel (3)\n",
    "<br>\n",
    "output size = n \\* n * number of filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple filters\n",
    "Maybe we have filter to detect horizontal edges, vertical edges, 45 degree edges, and so on and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling Layer\n",
    "\n",
    "### Max Pooling\n",
    "If this feature is detected anywhere in this filter, then keep a high number. If not detected so maybe this feature doesnt exist.<br>\n",
    "Hyperparameters:\n",
    "- f = filter size\n",
    "- s = stride\n",
    "\n",
    "No parameters to learn!<br>\n",
    "Number channel of image is same as the input and output<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classic Network\n",
    "\n",
    "### LeNet\n",
    "![LeNet](https://image.slidesharecdn.com/lenettoresnet-170509055515/95/lenet-to-resnet-3-638.jpg?cb=1494309688)\n",
    "\n",
    "### AlexNet\n",
    "![AlexNet](data:image/png;base64,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)\n",
    "\n",
    "### VGG16\n",
    "![VGG16](https://cdn-images-1.medium.com/max/1600/1*-lIw_z6HEPHaGSpSOhyBow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Network (ResNet)\n",
    "z<sup>[l+1]</sup> = W<sup>[l+1]</sup> a<sup>[l]</sup> + b<sup>[l+1]</sup> <br>\n",
    "a<sup>[l+1]</sup> = g(z<sup>[l+1]</sup>)<br>\n",
    "\n",
    "![ResNet](https://cdn-images-1.medium.com/max/1314/1*S3TlG0XpQZSIpoDIUCQ0RQ.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One By One Convolution (Network in Network)\n",
    "Convolution with 1x1 kernel size. Used for reducing image dimension in Inception network (Bottleneck Layer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception Network\n",
    "Combine convolution process with more than one kernel. InceptionNet having a high computational cost due to multiple convolution output.\n",
    "![Inception Network](resource/CNN/notes/Convolutional Neural Network - deeplearning.ai/img/inception.png)\n",
    "\n",
    "- Inception Network using One by One convolution to reduce the number of parameters (Bottleneck layer)\n",
    "![Inception Network](resource/CNN/notes/Convolutional Neural Network - deeplearning.ai/img/inception2.png)\n",
    "\n",
    "### Inception Module\n",
    "![Inception Module](resource/CNN/notes/Convolutional Neural Network - deeplearning.ai/img/inception3.png)\n",
    "\n",
    "### Example of Inception Architecture\n",
    "![Inception Architecture](https://devblogs.nvidia.com/wp-content/uploads/2015/08/image6.png)\n",
    "NB:\n",
    "- FC and Softmax Activation before the last layer used for make sure the intermediate layer not too bad for predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning\n",
    "Used someone trained CNN saved weight and change it as your need.\n",
    "![Transfer Learning](img/transfer learning.png)\n",
    "NB:\n",
    "- If you have small dataset based on your problem, change only the output layer based on your #class and keep the layer before it freeze (untrainable).\n",
    "- If you have medium to large dataset based on your problem, change the several first layer and change the output layer based on your #class.\n",
    "- If you have very very large dataset based on your problem, train all the network from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Augmentation\n",
    "In computer vision, the number of data is never enough. So, we generate new image based on condition we specify.\n",
    "![augmentation](img/augmentation.png)\n",
    "![color shifting](img/augmentation2.png)\n",
    "![distortion during training](img/augmentation4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips Winning Compteition\n",
    "![Tips Winning Competition](img/tips winning competition.png)\n",
    "NB: Don't use on production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
